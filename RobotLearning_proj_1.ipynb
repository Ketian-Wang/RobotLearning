{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ketian-Wang/RobotLearning/blob/main/RobotLearning_proj_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This project aims to demonstrate how classical machine learning methods can be used in robotics setting. This project will be working on a navigation agent that navigates inside a simple 2D maze.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?id=1mSpegY1psdek3Lgh6cxzcCGUCF-lddnV\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "The image above shows the simulation world. The \"robot\" (also called \"agent\") is shown by the green dot. The goal location is shown by the red square. The aim of the agent is to navigate to the goal.\n",
        "\n",
        "The ultimate goal in this project is to learn an appropriate behavior for the agent by imitating demonstrations from an expert user. These demonstrations have been collected by a human controlling the agent via a keyboard, and will be provided to you as training data.\n",
        "\n",
        "This project has 3 parts. The instructions for each part are below."
      ],
      "metadata": {
        "id": "on62OZpXBKKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 0. Project Setup\n"
      ],
      "metadata": {
        "id": "yfv6pTUGEm90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/roamlab/robot-learning-S2023.git\n",
        "!cp -av /content/robot-learning-S2023/project1/* /content/\n",
        "!pip install pybullet"
      ],
      "metadata": {
        "id": "LYtdJaVWOMER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fa29e0-5fd1-414c-8071-911a5a6913d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'robot-learning-S2023'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 44 (delta 12), reused 39 (delta 10), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), 129.23 KiB | 283.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1. Inferring the position of an agent with RGB images"
      ],
      "metadata": {
        "id": "m6kijhsXNoaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?id=1Cn2sAcz0sOXX5x1dvRCEtKCL5yJDYkKS\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "The first task is to learn to infer where the agent is inside the maze based on RGB image observations like the one shown above. Each such observation will consist of an RGB image of size [64, 64] for each color channel, so the total size of each observation is [64, 64, 3].\n",
        "\n",
        "The maze has its own coordinate system, in which the agent's location must be expressed. RGB image observations is provided in this environment, as well as the groundtruth location of the agent in each image, expressed in the maze coordinate system. The task is to learn a model that can predict the location of an agent given this RGB observation."
      ],
      "metadata": {
        "id": "HbsQ79WoHU9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# additional packages\n",
        "import pickle\n",
        "from sklearn.linear_model import LinearRegression as LR\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "class PositionRegressor():\n",
        "\n",
        "    print('start')\n",
        "\n",
        "    def train(self, data):\n",
        "        \"\"\"A method that trains a regressor with given data\n",
        "\n",
        "           Args:\n",
        "               data: a dictionary that contains images and the groundtruth location of\n",
        "                     an agent.\n",
        "           Returns:\n",
        "               Nothing\n",
        "        \"\"\"\n",
        "\n",
        "        # figure data\n",
        "        imgs = data['obs']\n",
        "        RBGarray = []\n",
        "        for image in imgs:\n",
        "            RBGarray.append(image.reshape(1, -1)[0])\n",
        "        RBGarray = np.array(RBGarray)\n",
        "\n",
        "        # ground truth\n",
        "        info = data['info']\n",
        "        agentPos = []\n",
        "        for pos in info:\n",
        "            agentPos.append(pos['agent_pos'])\n",
        "        agentPos = np.array(agentPos)\n",
        "\n",
        "        self.model = LR()\n",
        "        self.model.fit(RBGarray,agentPos)\n",
        "\n",
        "        print(\"Using dummy solution for PositionRegressor\")\n",
        "        pass\n",
        "\n",
        "    def predict(self, Xs):\n",
        "        \"\"\"A method that predicts y's given a batch of X's\n",
        "\n",
        "           Args:\n",
        "               Xs: a batch of data (in this project, it is in shape [batch_size, 64, 64, 3])\n",
        "           Returns:\n",
        "               The fed-forward results (predicted y's) with a trained model.\n",
        "        \"\"\"\n",
        "        xx = Xs.reshape(Xs.shape[0], -1)\n",
        "        result = self.model.predict(xx)\n",
        "\n",
        "        return result\n"
      ],
      "metadata": {
        "id": "uJdME_SVNnRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99ad04b-257e-493d-b329-8d41781b6b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Behavioral cloning with low dimensional data"
      ],
      "metadata": {
        "id": "POFHlL1xNx8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, your model is asked to determine what action the agent should take, based on an observation from its environment. The action can be one of three choices: go up, go left, or go right. The goal of the agent is to reach the goal squre, shown in red in the images above.\n",
        "\n",
        "This project will be working on an environment with a discrete action space, so behavioral cloning can be seen as a classification problem with three output classes (go up, go left, go right). While the action space is the same in Parts II and III, the nature of the observation used in each case will be different.\n",
        "\n",
        "In Part II, the observation will consist of the ground truth position of the agent in the maze coordinate system. Training data will thus contain tuples $(o, a)_i$  where $o$ is the agent's location in the maze, and $a$ is the action taken by the expert at that location."
      ],
      "metadata": {
        "id": "MW80lZu0Jr1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class POSBCRobot():\n",
        "    \n",
        "\n",
        "    def train(self, data):\n",
        "        \"\"\"A method for training a policy.\n",
        "\n",
        "            Args:\n",
        "                data: a dictionary that contains X (observations) and y (actions).\n",
        "            \n",
        "            Returns:\n",
        "                This method does not return anything. It will just need to update the\n",
        "                property of a RobotPolicy instance.\n",
        "        \"\"\"\n",
        "\n",
        "        # for key, val in data.items():\n",
        "            # print(key, val.shape)\n",
        "\n",
        "        # data read\n",
        "        agentPos = data['obs']\n",
        "        agentAction = data['actions']\n",
        "        agentAction = agentAction.reshape(-1)\n",
        "\n",
        "\n",
        "        self.svc=SVC(kernel='poly',degree=1,coef0=0)\n",
        "\n",
        "        self.svc.fit(agentPos, agentAction)\n",
        "\n",
        "\n",
        "        print(\"Using dummy solution for POSBCRobot\")\n",
        "        pass\n",
        "\n",
        "    def get_actions(self, observations):\n",
        "        \"\"\"A method for getting actions. You can do data preprocessing and feed\n",
        "            forward of your trained model here.\n",
        "            \n",
        "            Args:\n",
        "                observations: a batch of observations (images or vectors)\n",
        "            \n",
        "            Returns:\n",
        "                A batch of actions with the same batch size as observations.\n",
        "        \"\"\"\n",
        "        result = self.svc.predict(observations)\n",
        "\n",
        "        return result\n"
      ],
      "metadata": {
        "id": "OfTObQ5hN0gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3. Behavioral cloning with visual observations"
      ],
      "metadata": {
        "id": "CRtN8RuwN0zS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part the observations will be a lot more challenging to use. Instead of being provided with the actual robot location, the model will receive as input RGB image observations of the world."
      ],
      "metadata": {
        "id": "Ub_ejt1bL9NC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC,SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import KernelPCA\n",
        "\n",
        "\n",
        "class RGBBCRobot():\n",
        "\n",
        "\n",
        "    def train(self, data):\n",
        "        \"\"\"A method for training a policy.\n",
        "\n",
        "            Args:\n",
        "                data: a dictionary that contains X (observations) and y (actions).\n",
        "            \n",
        "            Returns:\n",
        "                This method does not return anything. It will just need to update the\n",
        "                property of a RobotPolicy instance.\n",
        "        \"\"\"\n",
        "\n",
        "        # for key, val in data.items():\n",
        "            # print(key, val.shape)\n",
        "\n",
        "        imgs = data['obs']\n",
        "        RGBarray = []\n",
        "        for image in imgs:\n",
        "            RGBarray.append(image.reshape(1, -1)[0])\n",
        "        RGBarray = np.array(RGBarray)\n",
        "\n",
        "        self.SScaler= StandardScaler()\n",
        "        self.SScaler.fit(RGBarray)\n",
        "        RGBarrayScaled = self.SScaler.transform(RGBarray)\n",
        "        \n",
        "        agentAction = data['actions']\n",
        "        agentAction = agentAction.reshape(-1)\n",
        "\n",
        "        self.KernelPCAmodel = KernelPCA(n_components=30, kernel='rbf')\n",
        "        self.KernelPCAmodel.fit(RGBarrayScaled)\n",
        "        RGBTransed = self.KernelPCAmodel.transform(RGBarrayScaled)\n",
        "        # print(RGBTransed)\n",
        "        # print(RGBTransed.shape)\n",
        "\n",
        "        self.svc = SVC(kernel='poly',degree=2, C=10, coef0=0.5)\n",
        "        self.svc.fit(RGBTransed, agentAction)\n",
        "\n",
        "\n",
        "        print(\"Using dummy solution for RGBBCRobot\")\n",
        "        pass\n",
        "\n",
        "    def get_actions(self, observations):\n",
        "        \"\"\"A method for getting actions. You can do data preprocessing and feed\n",
        "            forward of your trained model here.\n",
        "            \n",
        "            Args:\n",
        "                observations: a batch of observations (images or vectors)\n",
        "            \n",
        "            Returns:\n",
        "                A batch of actions with the same batch size as observations.\n",
        "        \"\"\"\n",
        "        obsScaler = self.SScaler.transform(observations)\n",
        "        obsTransed = self.KernelPCAmodel.transform(obsScaler)\n",
        "        resultSVC = self.svc.predict(obsTransed)\n",
        "\n",
        "        return resultSVC"
      ],
      "metadata": {
        "id": "9trpNkL8N3Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "\n",
        "A grader will be applied to generate the score for this project. \n",
        "\n",
        "**Grading Rubrics**\n",
        "\n",
        "**Part 1**\n",
        "\n",
        "- score >= 0.99, you get 5/5\n",
        "- score >= 0.95, you get 4/5\n",
        "- score >= 0.80, you get 2/5\n",
        "\n",
        "**Part 2**\n",
        "\n",
        "- score >= 0.99, you get 5/5\n",
        "- score >= 0.80, you get 3/5\n",
        "\n",
        "**Part 3**\n",
        "\n",
        "- score >= 0.99, you get 5/5 \n",
        "- score >= 0.90, you get 4/5 \n",
        "- score >= 0.80, you get 3/5\n",
        "- score >= 0.60. you get 2/5 "
      ],
      "metadata": {
        "id": "BHBv0jRpNgZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turn GUI on/off"
      ],
      "metadata": {
        "id": "NTBR5b_xrDS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gui = False"
      ],
      "metadata": {
        "id": "5UOXzIhFrGiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Score Policy (do NOT change)"
      ],
      "metadata": {
        "id": "NRuhidcFQaNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install numpngw"
      ],
      "metadata": {
        "id": "5x36MBlJpgTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d42954a-1760-4d60-b400-0c3e86cf6357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpngw\n",
            "  Downloading numpngw-0.1.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from numpngw) (1.21.6)\n",
            "Installing collected packages: numpngw\n",
            "Successfully installed numpngw-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from score_policy import *\n",
        "score_all_parts(POSBCRobot(), RGBBCRobot(), PositionRegressor(), gui_enable=gui)"
      ],
      "metadata": {
        "id": "5yxmcyyW4jvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887711b2-fd7e-4369-d06a-7a87ae386e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using dummy solution for POSBCRobot\n",
            "Using dummy solution for RGBBCRobot\n",
            "Using dummy solution for PositionRegressor\n",
            "\n",
            "\n",
            "\n",
            "--------SCORES--------\n",
            "Position regression: 5/5\n",
            "BC with positions: 5/5\n",
            "BC with rgb images: 5/5\n",
            "\n",
            "Final score: 15/15\n",
            "----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show GUI"
      ],
      "metadata": {
        "id": "8I3gqaxOnig0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "# Image(filename='pos_bc_anim.png', width=200, height=200)\n",
        "# Image(filename='rgb_bc_anim.png', width=200, height=200)"
      ],
      "metadata": {
        "id": "Vz3iUfjdVsxp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}