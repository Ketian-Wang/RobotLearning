{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ketian-Wang/RobotLearning/blob/main/%E2%80%9Crobot_learning_proj_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intruduction\n",
        "\n",
        "This project aims to demonstrate how neural networks can be used in a robotics setting. This project will continue using the 2D maze environment introduced in previous project and learn to navigate an agent to a goal. However, since neural networks can be more powerful models than the ones we had access to previously, we can afford to make some changes to the 2D maze environment and make the problem more difficult.  This project consists of three parts. Part I will be training a simple DNN, which will take as input the agent position and goal position. Parts II and III will be training CNNs which take as input an image of the environment, with the agent the goal depicted on it.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/roamlab/robot-learning-S2023/blob/main/project2/imgs/P1_side.png?raw=true\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "The image above shows the simulation world. The \"robot\" (also called \"agent\") is shown by the green dot. The goal location is shown by the red square. The agent is required to navigate to the goal. **Unlike the previous project, the robot and the goal are spawned at random positions in the maze.** Also, the action space now contains all four directions: 'up', 'down', 'left' and 'right'. Another change is that, in addition to the obstacle map shown above, we introduce two new obstacle maps as shown below. However, these new maps will not be used until Part III.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://github.com/roamlab/robot-learning-S2023/blob/main/project2/imgs/map1.png?raw=true\" width=\"300\"/>\n",
        "<img src=\"https://github.com/roamlab/robot-learning-S2023/blob/main/project2/imgs/map2.png?raw=true\" width=\"300\"/>\n",
        "<img src=\"https://github.com/roamlab/robot-learning-S2023/blob/main/project2/imgs/map3.png?raw=true\" width=\"300\"/>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "inY7y5CRo97q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 0. Project Setup"
      ],
      "metadata": {
        "id": "VG4pixR1quFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download from my own Google Drive!\n",
        "!pip install --upgrade gdown\n",
        "!gdown https://drive.google.com/drive/folders/1w-IBeDph_-CKacJBbXOsGwstJfa4-9Sh?usp=sharing --folder\n",
        "!cp -av /content/project2/* /content/\n",
        "!pip install pybullet==2.6.6 numpngw"
      ],
      "metadata": {
        "id": "LYtdJaVWOMER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273d2d88-11c9-4ffc-e033-6db1f0a3ec2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.26.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.4\n",
            "Retrieving folder list\n",
            "Retrieving folder 1s8rl59KNppjobL-sLAwKTp2ZiVGWqbsi data\n",
            "Processing file 1bwCL05Z3VKUG0wpnDvmjU2yG_huXzZ6e all_maps.pkl\n",
            "Processing file 17k4vNAs8d5eD5V1F1m0BZZkjvNjYyUCU map1.pkl\n",
            "Processing file 124WdMqP9R4cWxeTlyne6TBY_GP-kAUU0 data_utils.py\n",
            "Processing file 1wEMfNG6Yl7S5_01bATf-SujhIO3RgdGu dnn.py\n",
            "Retrieving folder 1q3SDrW_Lw6p3QEYyN6gNVCXMTXDVL0_F imgs\n",
            "Processing file 16P36tz3pDBQo_CzxHiLS_x9QEgALUOJa map1.png\n",
            "Processing file 1rakolV0hvNw6Cecnik3I_WlSILn8XqZI map2.png\n",
            "Processing file 1hhEhbqmh16XtO9QfTUpqunhXv1aJS_Q7 map3.png\n",
            "Processing file 1abKu-ad3pUk3lmhekyk2Nx6s_qrgQcIl P1_side.png\n",
            "Retrieving folder 1DcBBsQdHP5JkESMMM45_s4gBKdmgBC8e mjcf\n",
            "Retrieving folder 1D0ZY4Uadq78i1vQa3aE_0DzXSsRKxcba common\n",
            "Processing file 1qJ2OvJuEWWxlxALPgrhApmDLoUYgAI4S materials.xml\n",
            "Processing file 11u4lkjPf6fOaBLaKEDctdXulNIoBkJzF skybox.xml\n",
            "Processing file 1hpHKiResbyZ7E2OGY3IfAa-Toid1k8oj visual.xml\n",
            "Processing file 1UZb78zjryaYRnUg5ULEwfo5WEaPV-X6n point_mass.xml\n",
            "Processing file 1VoiMlGIrg7QDJ99gxh2TWsdgUE7ooeie test_mjcf.xml\n",
            "Processing file 1blN3hdxQGr9m5JoaRE9Af0ap1i8w2rWc score_policy.py\n",
            "Processing file 1Pfu4BTpWMhQBScW_E6ceiPg3QKYA6My1 simple_maze.py\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bwCL05Z3VKUG0wpnDvmjU2yG_huXzZ6e\n",
            "To: /content/project2/data/all_maps.pkl\n",
            "100% 1.18G/1.18G [00:05<00:00, 208MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17k4vNAs8d5eD5V1F1m0BZZkjvNjYyUCU\n",
            "To: /content/project2/data/map1.pkl\n",
            "100% 393M/393M [00:02<00:00, 163MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=124WdMqP9R4cWxeTlyne6TBY_GP-kAUU0\n",
            "To: /content/project2/data_utils.py\n",
            "100% 115/115 [00:00<00:00, 643kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wEMfNG6Yl7S5_01bATf-SujhIO3RgdGu\n",
            "To: /content/project2/dnn.py\n",
            "100% 3.89k/3.89k [00:00<00:00, 24.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16P36tz3pDBQo_CzxHiLS_x9QEgALUOJa\n",
            "To: /content/project2/imgs/map1.png\n",
            "100% 917/917 [00:00<00:00, 4.49MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rakolV0hvNw6Cecnik3I_WlSILn8XqZI\n",
            "To: /content/project2/imgs/map2.png\n",
            "100% 979/979 [00:00<00:00, 6.40MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hhEhbqmh16XtO9QfTUpqunhXv1aJS_Q7\n",
            "To: /content/project2/imgs/map3.png\n",
            "100% 897/897 [00:00<00:00, 4.73MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1abKu-ad3pUk3lmhekyk2Nx6s_qrgQcIl\n",
            "To: /content/project2/imgs/P1_side.png\n",
            "100% 15.6k/15.6k [00:00<00:00, 55.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qJ2OvJuEWWxlxALPgrhApmDLoUYgAI4S\n",
            "To: /content/project2/mjcf/common/materials.xml\n",
            "100% 1.11k/1.11k [00:00<00:00, 6.87MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11u4lkjPf6fOaBLaKEDctdXulNIoBkJzF\n",
            "To: /content/project2/mjcf/common/skybox.xml\n",
            "100% 203/203 [00:00<00:00, 1.00MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hpHKiResbyZ7E2OGY3IfAa-Toid1k8oj\n",
            "To: /content/project2/mjcf/common/visual.xml\n",
            "100% 176/176 [00:00<00:00, 1.15MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UZb78zjryaYRnUg5ULEwfo5WEaPV-X6n\n",
            "To: /content/project2/mjcf/point_mass.xml\n",
            "100% 1.08k/1.08k [00:00<00:00, 5.48MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VoiMlGIrg7QDJ99gxh2TWsdgUE7ooeie\n",
            "To: /content/project2/mjcf/test_mjcf.xml\n",
            "100% 300/300 [00:00<00:00, 1.41MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1blN3hdxQGr9m5JoaRE9Af0ap1i8w2rWc\n",
            "To: /content/project2/score_policy.py\n",
            "100% 2.69k/2.69k [00:00<00:00, 13.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Pfu4BTpWMhQBScW_E6ceiPg3QKYA6My1\n",
            "To: /content/project2/simple_maze.py\n",
            "100% 10.1k/10.1k [00:00<00:00, 35.5MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part I. Behavioral cloning with low dimensional data\n",
        "\n",
        "This part is a natural extension of Part II in Project 1.\n",
        "\n",
        "Learning the agent's policy here is the familiar classification problem, given that labeled examples from an expert will be provided. Each labeled example $i$ will contain a tuple of the form $(o, a)^i$, where $o$ represents an observation and $a$ represents the action taken by the expert given that observation. The part simply learn to imitate the expert, a process also known as behavioral cloning. While the action space is the same in all parts of the project, the observation space will be different. \n",
        "\n",
        "We will be training a DNN policy to predict an action to be taken ('up', 'down', 'left', and 'right') based on the observation. **In Part I, the observation will contain the agent position and the current goal position.** (Because the goal is sampled randomly, the policy has to know the current goal to be reached.) The environment thus returns an observation array of size (4, ) where the agent position is contained in the first two axes and the current goal position is contained in the next two. **In Part I, the map that the robot is navigating is always the same.**\n"
      ],
      "metadata": {
        "id": "Wz0ALBOu6coY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# base class\n",
        "\n",
        "import abc\n",
        "\n",
        "\n",
        "class RobotPolicy(abc.ABC):\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def train(self, data):\n",
        "        \"\"\"\n",
        "            Abstract method for training a policy.\n",
        "\n",
        "            Args:\n",
        "                data: a dict that contains X (key = 'obs') and y (key = 'actions').\n",
        "\n",
        "                X is either rgb image (N, 64, 64, 3) OR  agent & goal pos (N, 4)  \n",
        "\n",
        "            Returns:\n",
        "                This method does not return anything. It will just need to update the\n",
        "                property of a RobotPolicy instance.\n",
        "        \"\"\"\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def get_action(self, obs):\n",
        "        \"\"\"\n",
        "            Abstract method for getting action. You can do data preprocessing and feed\n",
        "            forward of your trained model here.\n",
        "            Args:\n",
        "                obs: an observation (64 x 64 x 3) rgb image OR (4, ) positions\n",
        "            \n",
        "            Returns:\n",
        "                action: an integer between 0 to 3\n",
        "        \"\"\""
      ],
      "metadata": {
        "id": "NAb3tE7h9uUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class MyDNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(MyDNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3 = nn.Linear(64, 16)\n",
        "        self.fc4 = nn.Linear(16, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "    def predict(self, features):\n",
        "        \"\"\"\n",
        "        Function receives a numpy array, converts to torch, returns numpy again\n",
        "        \"\"\"\n",
        "        self.eval()  # Sets network in eval mode (vs training mode)\n",
        "        features = torch.from_numpy(features).float()\n",
        "        return self.forward(features).detach().numpy()\n",
        "  \n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, labels, features):\n",
        "        super(MyDataset, self).__init__()\n",
        "        self.labels = labels\n",
        "        self.features = features\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.features.shape[0]\n",
        "\n",
        "    def __getitem__(self,\n",
        "                    idx):  # This tells torch how to extract a single datapoint from a dataset, Torch randomized and needs a way to get the nth-datapoint\n",
        "        feature = self.features[idx]\n",
        "        label = self.labels[idx]\n",
        "        return {'feature': feature, 'label': label}\n",
        "\n",
        "\n",
        "class MyDNNTrain(object):\n",
        "    def __init__(self, network): \n",
        "        self.network = network\n",
        "        self.learning_rate = 0.005\n",
        "        self.optimizer = torch.optim.Adam(self.network.parameters(), lr=self.learning_rate)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.num_epochs = 200\n",
        "        self.batchsize = 100\n",
        "        self.shuffle = True\n",
        "\n",
        "    def train(self, labels, features):\n",
        "        self.network.train()\n",
        "        dataset = MyDataset(labels, features)\n",
        "        loader = DataLoader(dataset, shuffle=self.shuffle, batch_size=self.batchsize)\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.train_epoch(loader)\n",
        "\n",
        "    def train_epoch(self, loader):\n",
        "        total_loss = 0.0\n",
        "        for i, data in enumerate(loader):\n",
        "            features = data['feature'].float()\n",
        "            labels = data['label'].long()\n",
        "            self.optimizer.zero_grad()\n",
        "            predictions = self.network.forward(features)\n",
        "            # print(predictions)\n",
        "            loss = self.criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            total_loss += loss.item()\n",
        "            self.optimizer.step()\n",
        "        print('loss', total_loss / i)\n",
        "\n",
        "\n",
        "class POSBCRobot(RobotPolicy):\n",
        "\n",
        "    def train(self, data):\n",
        "        for key, val in data.items():\n",
        "            print(key, val.shape)\n",
        "        print(\"Using dummy solution for POSBCRobot\")\n",
        "\n",
        "        #data input\n",
        "        AgentAction = data['actions']\n",
        "        labels = np.asarray(AgentAction)\n",
        "        labels = torch.from_numpy(labels)\n",
        "        # labels = F.one_hot(labels, num_classes=4)\n",
        "        # print(labels)\n",
        "\n",
        "\n",
        "        obs = data['obs']\n",
        "        # features = np.asarray(obs)\n",
        "        obs = torch.from_numpy(obs).float()\n",
        "        # print(labels)\n",
        "        # print(type(features))\n",
        "\n",
        "\n",
        "        self.network = MyDNN(4)\n",
        "        self.trainer = MyDNNTrain(self.network)\n",
        "        self.trainer.train(labels, obs)\n",
        "\n",
        "        pass \n",
        "\n",
        "    def get_action(self, obs):\n",
        "        self.network.eval()\n",
        "        action = self.network.predict(obs)\n",
        "        return np.argmax(action)"
      ],
      "metadata": {
        "id": "ZH35w1j-Y7t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation and Grading\n",
        "\n",
        "The model will be evaluated by simply having the agent follow the commands that it provides. 100 different randomly sampled starting positions and goals will be tested. Each goal rolls out the trained policy for 50 steps. After the 50 steps, we will evaluate the closest distance to the goal the agent has ended up. If the agent reaches < 0.1 distance from the goal, the episode is ended before 50 steps and the minimum distance will be recorded as 0. The score is the fraction of the initial distance to goal covered by the agent averaged over 100 trials. Your final grade will be computed based on this score.\n",
        "\n",
        "The score will be calculated using the formula :\n",
        "\n",
        "```score = avg[(init_dist -  min_dist) / init_dist]```\n",
        "\n",
        "The total points of this assignment are 15. According to the difficulty level of each part, parts 1, 2, and 3 have 4, 5, 6 points respectively. \n",
        "\n",
        "- Part 1: if your score >= 0.99, you will receive 4 / 4. Otherwise, your final grade will be score / 0.99 * 4.\n",
        "- Part 2: if your score >= 0.95, you will receive 5 / 5. Otherwise, your final grade will be score / 0.95 * 5.\n",
        "- Part 3: if your score >= 0.95, you will receive 6 / 6. Otherwise, your final grade will be score / 0.95 * 6.\n"
      ],
      "metadata": {
        "id": "JLchnZGWZYeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import score_policy\n",
        "import importlib\n",
        "importlib.reload(score_policy)\n",
        "from IPython.display import Image\n",
        "\n",
        "\n",
        "part1_bound = 0.99\n",
        "part2_bound = 0.95\n",
        "part3_bound = 0.95"
      ],
      "metadata": {
        "id": "ZporTBmpmahZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score1 = score_policy.score_pos_bc(policy=POSBCRobot(), gui=False, model=None)\n",
        "grade1 = score1 / part1_bound * 4 if score1 < part1_bound else 4\n",
        "\n",
        "print('\\n---')\n",
        "print(f'Part 1 Score: {score1}')\n",
        "print(f'Part 1 Grade: {score1:.2f} / {part1_bound:.2f} * 4 = {grade1:.2f}')"
      ],
      "metadata": {
        "id": "-c-Ob4uUlRM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f19deae4-ea2c-445d-f09c-7cda5561c420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actions (4000,)\n",
            "obs (4000, 4)\n",
            "Using dummy solution for POSBCRobot\n",
            "loss 0.9775175635631268\n",
            "loss 0.6955564786226321\n",
            "loss 0.5940810869901608\n",
            "loss 0.505073220301897\n",
            "loss 0.4466643998256096\n",
            "loss 0.4194487096407475\n",
            "loss 0.4042717348306607\n",
            "loss 0.3944137421173927\n",
            "loss 0.39177782642535675\n",
            "loss 0.38042136339040905\n",
            "loss 0.36642322402734023\n",
            "loss 0.387549720513515\n",
            "loss 0.3570115061906668\n",
            "loss 0.3440079601147236\n",
            "loss 0.3507527773961043\n",
            "loss 0.3380996535221736\n",
            "loss 0.3305549598657168\n",
            "loss 0.33064373563497496\n",
            "loss 0.32209540750735843\n",
            "loss 0.316408247137681\n",
            "loss 0.31713431920760715\n",
            "loss 0.33212955334247685\n",
            "loss 0.3042853860518871\n",
            "loss 0.30718862322660595\n",
            "loss 0.2901652094263297\n",
            "loss 0.29669795968593693\n",
            "loss 0.28822548878498566\n",
            "loss 0.2967775483161975\n",
            "loss 0.282771103657209\n",
            "loss 0.28695253072640836\n",
            "loss 0.28090505378368574\n",
            "loss 0.2693265752914624\n",
            "loss 0.26178984114756954\n",
            "loss 0.2662335550173735\n",
            "loss 0.25954637160668004\n",
            "loss 0.2658908038567274\n",
            "loss 0.25278833966988784\n",
            "loss 0.24796549746623406\n",
            "loss 0.2391530332657007\n",
            "loss 0.2518904010454814\n",
            "loss 0.2509637923958974\n",
            "loss 0.23738165543629572\n",
            "loss 0.2484947043733719\n",
            "loss 0.23316392264305016\n",
            "loss 0.2351372494147374\n",
            "loss 0.23094242753890845\n",
            "loss 0.22636775576915497\n",
            "loss 0.22468618933971113\n",
            "loss 0.22674899319043526\n",
            "loss 0.23410905209871438\n",
            "loss 0.24244026725108808\n",
            "loss 0.22690623864913598\n",
            "loss 0.2105651992635849\n",
            "loss 0.21381127948944384\n",
            "loss 0.20443494274066046\n",
            "loss 0.21547612929955506\n",
            "loss 0.22278114064381674\n",
            "loss 0.20918655796692923\n",
            "loss 0.22392936853262094\n",
            "loss 0.21011879715399864\n",
            "loss 0.205440498315371\n",
            "loss 0.21340643232449508\n",
            "loss 0.22037463501477852\n",
            "loss 0.21375256452040794\n",
            "loss 0.20836691042551628\n",
            "loss 0.2072430161329416\n",
            "loss 0.21684595961601305\n",
            "loss 0.19604221941568914\n",
            "loss 0.20176499470686302\n",
            "loss 0.1918331862260134\n",
            "loss 0.19839367748070985\n",
            "loss 0.19335233496549803\n",
            "loss 0.19211888294189405\n",
            "loss 0.2066039324570925\n",
            "loss 0.19056617621427926\n",
            "loss 0.19707510696771818\n",
            "loss 0.1870535514675654\n",
            "loss 0.193464457988739\n",
            "loss 0.19398401906857124\n",
            "loss 0.1840667296678592\n",
            "loss 0.190816961037807\n",
            "loss 0.19121601871955088\n",
            "loss 0.180674200065625\n",
            "loss 0.18570543902042586\n",
            "loss 0.17842995127042136\n",
            "loss 0.1800695757071177\n",
            "loss 0.17847633017943457\n",
            "loss 0.19115702884319502\n",
            "loss 0.19280992792202875\n",
            "loss 0.1851709620692791\n",
            "loss 0.18163159623360023\n",
            "loss 0.1824580354568286\n",
            "loss 0.18815838660185152\n",
            "loss 0.17914428112980646\n",
            "loss 0.177355768206792\n",
            "loss 0.17190748071059203\n",
            "loss 0.1799453298250834\n",
            "loss 0.16581747107780898\n",
            "loss 0.16444159862704766\n",
            "loss 0.17645460902116236\n",
            "loss 0.17821006706127754\n",
            "loss 0.16664456958189988\n",
            "loss 0.1739295929288253\n",
            "loss 0.17283588810226855\n",
            "loss 0.16279862649165666\n",
            "loss 0.1611465306427234\n",
            "loss 0.16692515787405846\n",
            "loss 0.16317927111417818\n",
            "loss 0.16000309128027695\n",
            "loss 0.15628622300349748\n",
            "loss 0.15816531884364593\n",
            "loss 0.15485558697046378\n",
            "loss 0.15891803285250297\n",
            "loss 0.1542471041664099\n",
            "loss 0.15432974524222887\n",
            "loss 0.15743205295159265\n",
            "loss 0.14817840510453933\n",
            "loss 0.15637207289154714\n",
            "loss 0.16381455136415285\n",
            "loss 0.16484606323333886\n",
            "loss 0.15925274111139467\n",
            "loss 0.15508920145340455\n",
            "loss 0.1436654147811425\n",
            "loss 0.15904071592749694\n",
            "loss 0.15535907428234053\n",
            "loss 0.15427278068203193\n",
            "loss 0.16888643419131255\n",
            "loss 0.148576870178565\n",
            "loss 0.1486169421711029\n",
            "loss 0.14383908151051936\n",
            "loss 0.14452064572236475\n",
            "loss 0.1531581978003184\n",
            "loss 0.14644332306507307\n",
            "loss 0.15867188744820082\n",
            "loss 0.1467627342312764\n",
            "loss 0.13862925357161424\n",
            "loss 0.14019932941748545\n",
            "loss 0.138293152818313\n",
            "loss 0.13500688129510635\n",
            "loss 0.1420635026999009\n",
            "loss 0.15444001001425278\n",
            "loss 0.15155194260371038\n",
            "loss 0.15301828392041036\n",
            "loss 0.14357675354068095\n",
            "loss 0.1464583829809458\n",
            "loss 0.14074479970030296\n",
            "loss 0.15063581663446549\n",
            "loss 0.1470314405667476\n",
            "loss 0.14275167700953972\n",
            "loss 0.13505035046583566\n",
            "loss 0.14556413650130615\n",
            "loss 0.13043531087728646\n",
            "loss 0.12291318942338993\n",
            "loss 0.12966562778903887\n",
            "loss 0.13037144392728806\n",
            "loss 0.13010669289491114\n",
            "loss 0.13778176435675377\n",
            "loss 0.14236812178905195\n",
            "loss 0.13552380467836672\n",
            "loss 0.12297599533429512\n",
            "loss 0.13039785088636938\n",
            "loss 0.13801956950471952\n",
            "loss 0.13848790703102565\n",
            "loss 0.1281538785268099\n",
            "loss 0.12935248657296866\n",
            "loss 0.12890723624672645\n",
            "loss 0.12234124044577281\n",
            "loss 0.1278418522232618\n",
            "loss 0.1221418220263261\n",
            "loss 0.13522818121008384\n",
            "loss 0.13492935265486056\n",
            "loss 0.1293769714732965\n",
            "loss 0.13123822489228004\n",
            "loss 0.1283013489192877\n",
            "loss 0.1309307266313296\n",
            "loss 0.1290946111847193\n",
            "loss 0.13004339094727468\n",
            "loss 0.11389986912791546\n",
            "loss 0.12436686389339276\n",
            "loss 0.11575993599417882\n",
            "loss 0.12343939938224278\n",
            "loss 0.12174220211230792\n",
            "loss 0.10828363627959521\n",
            "loss 0.11883083778696182\n",
            "loss 0.11774569081190304\n",
            "loss 0.13408465463763627\n",
            "loss 0.12550368074041146\n",
            "loss 0.11320310515853074\n",
            "loss 0.11385264887641637\n",
            "loss 0.1535974570000783\n",
            "loss 0.16217521004951918\n",
            "loss 0.1199811129615857\n",
            "loss 0.11103836370584293\n",
            "loss 0.11335152167922412\n",
            "loss 0.09806135277717541\n",
            "loss 0.10167562273832467\n",
            "loss 0.12271743793136035\n",
            "loss 0.11950336816983345\n",
            "loss 0.1121164443783271\n",
            "loss 0.10325864540078701\n",
            "\n",
            "---\n",
            "Part 1 Score: 1.0\n",
            "Part 1 Grade: 1.00 / 0.99 * 4 = 4.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II. Behavioral cloning with visual observations\n",
        "\n",
        "In this part, the task is similar to that in Part I, **but the observations will be RGB image observations of the world**, similar to the ones which was used to do localization in Part III of Project 1. To process the RGB image a CNN is implemneted using PyTorch.  [The official PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) is a good starting point. As in Part I, the map that the robot is navigating is always the same. **This means that the model really only has to learn how to figure out where the robot and the goal are located, and how to navigate around a fixed set of obstacles.**\n"
      ],
      "metadata": {
        "id": "3s-mYCwfZql_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class MyCNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(2704, 512)\n",
        "        self.fc2 = nn.Linear(512, 64)\n",
        "        self.fc3 = nn.Linear(64, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def predict(self, features):\n",
        "        \"\"\"\n",
        "        Function receives a numpy array, converts to torch, returns numpy again\n",
        "        \"\"\"\n",
        "        self.eval()  # Sets network in eval mode (vs training mode)\n",
        "        features = torch.from_numpy(features).float()\n",
        "        return self.forward(features).detach().numpy()\n",
        "  \n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, labels, features):\n",
        "        super(MyDataset, self).__init__()\n",
        "        self.labels = labels\n",
        "        self.features = features\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.features.shape[0]\n",
        "\n",
        "    def __getitem__(self,\n",
        "                    idx):  # This tells torch how to extract a single datapoint from a dataset, Torch randomized and needs a way to get the nth-datapoint\n",
        "        feature = self.features[idx]\n",
        "        label = self.labels[idx]\n",
        "        return {'feature': feature, 'label': label}\n",
        "\n",
        "\n",
        "class MyCNNTrain(object):\n",
        "    def __init__(self, network):  \n",
        "        self.network = network\n",
        "        self.learning_rate = 0.01\n",
        "        self.optimizer = torch.optim.SGD(self.network.parameters(), lr=self.learning_rate, momentum = 0.9)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.num_epochs = 100\n",
        "        self.batchsize = 100\n",
        "        self.shuffle = True\n",
        "\n",
        "    def train(self, labels, features):\n",
        "        self.network.train()\n",
        "        dataset = MyDataset(labels, features)\n",
        "        loader = DataLoader(dataset, shuffle=self.shuffle, batch_size=self.batchsize)\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.train_epoch(loader)\n",
        "\n",
        "    def train_epoch(self, loader):\n",
        "        total_loss = 0.0\n",
        "        for i, data in enumerate(loader):\n",
        "            features = data['feature'].float()\n",
        "            labels = data['label'].long()\n",
        "            self.optimizer.zero_grad()\n",
        "            predictions = self.network.forward(features)\n",
        "            # print(predictions)\n",
        "            loss = self.criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            total_loss += loss.item()\n",
        "            self.optimizer.step()\n",
        "        print('loss', total_loss / i)\n",
        "\n",
        "\n",
        "\n",
        "class RGBBCRobot1(RobotPolicy):\n",
        "\n",
        "    def train(self, data):\n",
        "        for key, val in data.items():\n",
        "            print(key, val.shape)\n",
        "        print(\"Using dummy solution for RGBBCRobot1\")\n",
        "        AgentAction = data['actions']\n",
        "        labels = np.asarray(AgentAction)\n",
        "        labels = torch.from_numpy(labels)\n",
        "        # labels = F.one_hot(labels, num_classes=4)\n",
        "        print(labels)\n",
        "\n",
        "\n",
        "        obs = data['obs']\n",
        "        obs = obs.transpose((0,3,1,2))\n",
        "        obs = torch.from_numpy(obs).float()\n",
        "        print(obs.shape)\n",
        "\n",
        "        self.network = MyCNN()\n",
        "        self.trainer = MyCNNTrain(self.network)\n",
        "        self.trainer.train(labels, obs)\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def get_action(self, obs):\n",
        "        self.network.eval()\n",
        "        obs = obs.transpose((2,0,1))\n",
        "        # print(obs.shape)\n",
        "        obs = torch.from_numpy(obs).float()\n",
        "        obs = obs.unsqueeze(0)\n",
        "        # print(obs.shape)\n",
        "        obs = obs.numpy()\n",
        "        action = self.network.predict(obs)\n",
        "        return np.argmax(action)"
      ],
      "metadata": {
        "id": "Y9VmDjXiagTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation and Grading"
      ],
      "metadata": {
        "id": "cj5Xje--lkiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score2 = score_policy.score_rgb_bc1(policy=RGBBCRobot1(), gui=False, model=None)\n",
        "grade2 = score2 / part2_bound * 5 if score2 < part2_bound else 5\n",
        "\n",
        "print('\\n---')\n",
        "print(f'Part 2 Score: {score2}')\n",
        "print(f'Part 2 Grade: {score2:.2f} / {part2_bound:.2f} * 5 = {grade2:.2f}')"
      ],
      "metadata": {
        "id": "Y2kSdH99oESr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357da39c-dff5-46c7-9f19-76bf6250cc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actions (4000,)\n",
            "obs (4000, 64, 64, 3)\n",
            "Using dummy solution for RGBBCRobot1\n",
            "tensor([0, 0, 0,  ..., 2, 2, 3])\n",
            "torch.Size([4000, 3, 64, 64])\n",
            "loss 1.4167950397882707\n",
            "loss 1.4151402497902894\n",
            "loss 1.412885302152389\n",
            "loss 1.4051742217479608\n",
            "loss 1.3384582293339264\n",
            "loss 1.0823844701815875\n",
            "loss 1.0128055062049475\n",
            "loss 0.990216137507023\n",
            "loss 0.9802308953725375\n",
            "loss 0.9723199881040133\n",
            "loss 0.9707029171479054\n",
            "loss 0.9575655857721964\n",
            "loss 0.950916038109706\n",
            "loss 0.9492045381130316\n",
            "loss 0.9452001773394071\n",
            "loss 0.9375186944619204\n",
            "loss 0.932464232811561\n",
            "loss 0.9236517319312463\n",
            "loss 0.9294846485822629\n",
            "loss 0.9205345205771618\n",
            "loss 0.9160658350357642\n",
            "loss 0.9064350601954337\n",
            "loss 0.9015761904227428\n",
            "loss 0.8973910136100574\n",
            "loss 0.8913263663267478\n",
            "loss 0.8950373652653817\n",
            "loss 0.8866803630804404\n",
            "loss 0.87954803613516\n",
            "loss 0.8780925717109289\n",
            "loss 0.8786089145220243\n",
            "loss 0.8693983249175243\n",
            "loss 0.8657529155413309\n",
            "loss 0.8611573179562887\n",
            "loss 0.8581631091924814\n",
            "loss 0.8503025892453316\n",
            "loss 0.8479902056547312\n",
            "loss 0.8427951977803156\n",
            "loss 0.8466072265918438\n",
            "loss 0.8290389791513101\n",
            "loss 0.8268833878712777\n",
            "loss 0.8211724849847647\n",
            "loss 0.806019549186413\n",
            "loss 0.7863837954325553\n",
            "loss 0.7284563122651516\n",
            "loss 0.7132461414887354\n",
            "loss 0.5712174681516794\n",
            "loss 0.4757560705527281\n",
            "loss 0.3834773401419322\n",
            "loss 0.3022371584024185\n",
            "loss 0.24947766291025358\n",
            "loss 0.19405458848445845\n",
            "loss 0.16461221596751457\n",
            "loss 0.139085998519873\n",
            "loss 0.13228445404615158\n",
            "loss 0.12219550708929698\n",
            "loss 0.08537587580772546\n",
            "loss 0.0642579244210934\n",
            "loss 0.06623143177383985\n",
            "loss 0.04687116412111582\n",
            "loss 0.039284737494129404\n",
            "loss 0.050412980147088185\n",
            "loss 0.03853848941910725\n",
            "loss 0.028727267027044527\n",
            "loss 0.030272737467804782\n",
            "loss 0.024600815780174274\n",
            "loss 0.021135031239678845\n",
            "loss 0.01820441901994248\n",
            "loss 0.01896544287984188\n",
            "loss 0.016623565162985753\n",
            "loss 0.014495312734745825\n",
            "loss 0.011503105651802169\n",
            "loss 0.013319140640445627\n",
            "loss 0.0218912045029589\n",
            "loss 0.01442268708995424\n",
            "loss 0.011870628813854776\n",
            "loss 0.011180070861696433\n",
            "loss 0.009101758499104435\n",
            "loss 0.01053899277944882\n",
            "loss 0.011949340600926334\n",
            "loss 0.011341333132571517\n",
            "loss 0.010628385290963193\n",
            "loss 0.010977562613940487\n",
            "loss 0.010312889739930725\n",
            "loss 0.00941342712403872\n",
            "loss 0.007239719178193273\n",
            "loss 0.011475051124878705\n",
            "loss 0.011624827669061815\n",
            "loss 0.01199556439398573\n",
            "loss 0.010265826205842389\n",
            "loss 0.008590729762382137\n",
            "loss 0.008103190552598486\n",
            "loss 0.008240383142271103\n",
            "loss 0.010176805089800976\n",
            "loss 0.007996707583049264\n",
            "loss 0.008430160264908455\n",
            "loss 0.00871020441618151\n",
            "loss 0.007081392349508137\n",
            "loss 0.008052501749868194\n",
            "loss 0.007932544398593167\n",
            "loss 0.007958827032827033\n",
            "\n",
            "---\n",
            "Part 2 Score: 1.0\n",
            "Part 2 Grade: 1.00 / 0.95 * 5 = 5.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part III. Behavioral cloning with visual observations - multiple maps\n",
        "\n",
        "This part is the same as  Part II except that it is trained and tested differently. **The training set involves expert demonstrations for the two new obstacle maps. And while testing, for each trial, a different obstacle map is randomly selected.** This means that the model has to learn how to reason about what an obstacle is, and how to go around it, based on nothing more than an image. The main objective of this part is to show that, when using a CNN, it is possible for a model to achieve this. The evaluation method for this part is the same as Part I and II."
      ],
      "metadata": {
        "id": "1I6v1TgCctRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class MyCNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(2704, 512)\n",
        "        self.fc2 = nn.Linear(512, 64)\n",
        "        self.fc3 = nn.Linear(64, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def predict(self, features):\n",
        "        \"\"\"\n",
        "        Function receives a numpy array, converts to torch, returns numpy again\n",
        "        \"\"\"\n",
        "        self.eval()  # Sets network in eval mode (vs training mode)\n",
        "        features = torch.from_numpy(features).float()\n",
        "        return self.forward(features).detach().numpy()\n",
        "  \n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, labels, features):\n",
        "        super(MyDataset, self).__init__()\n",
        "        self.labels = labels\n",
        "        self.features = features\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.features.shape[0]\n",
        "\n",
        "    def __getitem__(self,\n",
        "                    idx):  # This tells torch how to extract a single datapoint from a dataset, Torch randomized and needs a way to get the nth-datapoint\n",
        "        feature = self.features[idx]\n",
        "        label = self.labels[idx]\n",
        "        return {'feature': feature, 'label': label}\n",
        "\n",
        "\n",
        "class MyCNNTrain(object):\n",
        "    def __init__(self, network):  # Networks is of datatype MyDNN\n",
        "        self.network = network\n",
        "        self.learning_rate = 0.01\n",
        "        self.optimizer = torch.optim.SGD(self.network.parameters(), lr=self.learning_rate, momentum = 0.9)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.num_epochs = 40\n",
        "        self.batchsize = 100\n",
        "        self.shuffle = True\n",
        "\n",
        "    def train(self, labels, features):\n",
        "        self.network.train()\n",
        "        dataset = MyDataset(labels, features)\n",
        "        loader = DataLoader(dataset, shuffle=self.shuffle, batch_size=self.batchsize)\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.train_epoch(loader)\n",
        "\n",
        "    def train_epoch(self, loader):\n",
        "        total_loss = 0.0\n",
        "        for i, data in enumerate(loader):\n",
        "            features = data['feature'].float()\n",
        "            labels = data['label'].long()\n",
        "            self.optimizer.zero_grad()\n",
        "            predictions = self.network.forward(features)\n",
        "            # print(predictions)\n",
        "            loss = self.criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            total_loss += loss.item()\n",
        "            self.optimizer.step()\n",
        "        print('loss', total_loss / i)\n",
        "\n",
        "\n",
        "\n",
        "class RGBBCRobot2(RobotPolicy):\n",
        "\n",
        "    def train(self, data):\n",
        "        for key, val in data.items():\n",
        "            print(key, val.shape)\n",
        "        print(\"Using dummy solution for RGBBCRobot1\")\n",
        "        AgentAction = data['actions']\n",
        "        labels = np.asarray(AgentAction)\n",
        "        labels = torch.from_numpy(labels)\n",
        "        # labels = F.one_hot(labels, num_classes=4)\n",
        "        print(labels)\n",
        "\n",
        "\n",
        "        obs = data['obs']\n",
        "        obs = obs.transpose((0,3,1,2))\n",
        "        obs = torch.from_numpy(obs).float()\n",
        "        print(obs.shape)\n",
        "\n",
        "        self.network = MyCNN()\n",
        "        self.trainer = MyCNNTrain(self.network)\n",
        "        self.trainer.train(labels, obs)\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def get_action(self, obs):\n",
        "        self.network.eval()\n",
        "        obs = obs.transpose((2,0,1))\n",
        "        # print(obs.shape)\n",
        "        obs = torch.from_numpy(obs).float()\n",
        "        obs = obs.unsqueeze(0)\n",
        "        # print(obs.shape)\n",
        "        obs = obs.numpy()\n",
        "        action = self.network.predict(obs)\n",
        "        return np.argmax(action)\n"
      ],
      "metadata": {
        "id": "AxQwN2MAdO09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation and Grading\n"
      ],
      "metadata": {
        "id": "aAky_Vu9l_EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "core3 = score_policy.score_rgb_bc2(policy=RGBBCRobot2(), gui=False, model=None)\n",
        "grade3 = score3 / part3_bound * 6 if score3 < part3_bound else 6\n",
        "\n",
        "print('\\n---')\n",
        "print(f'Part 3 Score: {score3}')\n",
        "print(f'Part 3 Grade: {score3:.2f} / {part3_bound:.2f} * 6 = {grade3:.2f}')"
      ],
      "metadata": {
        "id": "PM4edyLqpT3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c25c01b9-59d0-475d-a9c9-a0bd338f024f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actions (12000,)\n",
            "obs (12000, 64, 64, 3)\n",
            "Using dummy solution for RGBBCRobot1\n",
            "tensor([0, 0, 0,  ..., 1, 0, 0])\n",
            "torch.Size([12000, 3, 64, 64])\n",
            "loss 1.3802767070401616\n",
            "loss 1.3548624124847541\n",
            "loss 1.2919049202894963\n",
            "loss 1.11726879572668\n",
            "loss 1.085056000396985\n",
            "loss 1.0753861275039802\n",
            "loss 1.0629730655365632\n",
            "loss 1.055064192339152\n",
            "loss 1.0435278701181172\n",
            "loss 1.0304056255757308\n",
            "loss 0.9303386046105072\n",
            "loss 0.5912367744105202\n",
            "loss 0.3969051444730839\n",
            "loss 0.2788687447289459\n",
            "loss 0.24782643561102763\n",
            "loss 0.1995091384448925\n",
            "loss 0.1694784928895846\n",
            "loss 0.14901856120143617\n",
            "loss 0.13251018586779842\n",
            "loss 0.11747746507660682\n",
            "loss 0.10194553744767894\n",
            "loss 0.09707912672780641\n",
            "loss 0.08538869603247452\n",
            "loss 0.08032164884684216\n",
            "loss 0.07215447633081123\n",
            "loss 0.06717237683811358\n",
            "loss 0.059370339777664975\n",
            "loss 0.06173123870858876\n",
            "loss 0.05109305284573\n",
            "loss 0.04842735465788165\n",
            "loss 0.04214916330128282\n",
            "loss 0.040242882928724924\n",
            "loss 0.03994752047387805\n",
            "loss 0.036052964921226775\n",
            "loss 0.033973311604305854\n",
            "loss 0.0278209551969277\n",
            "loss 0.02643184576715742\n",
            "loss 0.026632876063016158\n",
            "loss 0.026002087896423682\n",
            "loss 0.02430462757293761\n",
            "\n",
            "---\n",
            "Part 3 Score: 0.9701404263564618\n",
            "Part 3 Grade: 0.97 / 0.95 * 6 = 6.00\n"
          ]
        }
      ]
    }
  ]
}